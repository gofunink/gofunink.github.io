<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>gofunink&#39;s blog</title>
  <icon>https://www.gravatar.com/avatar/dbcc855f3e28cacfe527c9115d217c92</icon>
  <subtitle>才高粑斗，学负五车</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.gofunink.com/"/>
  <updated>2019-04-09T06:28:39.922Z</updated>
  <id>https://www.gofunink.com/</id>
  
  <author>
    <name>gofunink</name>
    <email>gofun@189.cn</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySql实现ROW_NUMBER()开窗函数</title>
    <link href="https://www.gofunink.com/2019/04/09/MySql%E5%AE%9E%E7%8E%B0ROW_NUMBER()%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0/"/>
    <id>https://www.gofunink.com/2019/04/09/MySql实现ROW_NUMBER()开窗函数/</id>
    <published>2019-04-09T06:27:00.000Z</published>
    <updated>2019-04-09T06:28:39.922Z</updated>
    
    <content type="html"><![CDATA[<p>本文咱们使用mysql实现开窗函数row_number() over (partition by xxx,xxx order by xxx)，废话不多说，直接开干</p><h5 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h5> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from test_biz_policy_policy;</span><br></pre></td></tr></table></figure><table><thead><tr><th>platform_id（平台id）</th><th>publish_time（政策发布时间）</th><th>policy_name（政策名称）</th></tr></thead><tbody><tr><td>2</td><td>2019-04-01 15:11:06</td><td>test0</td></tr><tr><td>2</td><td>2019-04-01 19:11:06</td><td>test9</td></tr><tr><td>2</td><td>2019-04-01 19:11:06</td><td>test8</td></tr><tr><td>2</td><td>2019-04-01 18:11:06</td><td>test7</td></tr><tr><td>2</td><td>2019-04-01 15:11:06</td><td>test1</td></tr><tr><td>2</td><td>2019-04-01 15:11:06</td><td>test2</td></tr><tr><td>2</td><td>2019-04-01 16:11:06</td><td>test3</td></tr><tr><td>2</td><td>2019-04-01 16:11:06</td><td>test4</td></tr><tr><td>2</td><td>2019-04-01 16:11:06</td><td>test5</td></tr><tr><td>2</td><td>2019-04-01 17:11:06</td><td>test6</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>fengyu</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>新建政策1111111</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>1218测试</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>xxx</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>ccc</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>测试114</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>测试mmm</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>k k k k k k k</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>k k k k k k k明明</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>ceshi111</td></tr></tbody></table><h5 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h5><p>简而言之，就是以「平台id」,「政策发布时间」分组，根据「政策名称」进行排序，取政策前三名。<br><a id="more"></a></p><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">SELECT</span><br><span class="line">t.platform_id,</span><br><span class="line">t.publish_time,</span><br><span class="line">t.policy_name,</span><br><span class="line">t.rank_no </span><br><span class="line">FROM</span><br><span class="line">(</span><br><span class="line">SELECT</span><br><span class="line">a.platform_id,</span><br><span class="line">a.publish_time,</span><br><span class="line">a.policy_name,</span><br><span class="line">IF</span><br><span class="line">(</span><br><span class="line">@str1 = a.platform_id </span><br><span class="line">AND @str2 = a.publish_time,</span><br><span class="line">@rank := @rank + 1,</span><br><span class="line">@rank := 1 </span><br><span class="line">) AS rank_no,</span><br><span class="line">@str1 := a.platform_id,</span><br><span class="line">@str2 := a.publish_time </span><br><span class="line">FROM</span><br><span class="line">(</span><br><span class="line">SELECT</span><br><span class="line">platform_id,</span><br><span class="line">publish_time,</span><br><span class="line">policy_name </span><br><span class="line">FROM</span><br><span class="line">test_biz_policy_policy </span><br><span class="line">ORDER BY</span><br><span class="line">platform_id,</span><br><span class="line">publish_time,</span><br><span class="line">policy_name ASC </span><br><span class="line">) a,</span><br><span class="line">(</span><br><span class="line">SELECT</span><br><span class="line">@str1 := 0,</span><br><span class="line">@str2 := NULL,</span><br><span class="line">@rank := 0 </span><br><span class="line">) tmp </span><br><span class="line">) t </span><br><span class="line">WHERE</span><br><span class="line">t.rank_no &lt;= 5</span><br></pre></td></tr></table></figure><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><table><thead><tr><th>platform_id（平台id）</th><th>publish_time（政策发布时间）</th><th>policy_name（政策名称）</th></tr></thead><tbody><tr><td>2</td><td>2019-04-01 15:11:06</td><td>test0</td></tr><tr><td>2</td><td>2019-04-01 15:11:06</td><td>test1</td></tr><tr><td>2</td><td>2019-04-01 15:11:06</td><td>test2</td></tr><tr><td>2</td><td>2019-04-01 16:11:06</td><td>test3</td></tr><tr><td>2</td><td>2019-04-01 16:11:06</td><td>test4</td></tr><tr><td>2</td><td>2019-04-01 16:11:06</td><td>test5</td></tr><tr><td>2</td><td>2019-04-01 17:11:06</td><td>test6</td></tr><tr><td>2</td><td>2019-04-01 18:11:06</td><td>test7</td></tr><tr><td>2</td><td>2019-04-01 19:11:06</td><td>test8</td></tr><tr><td>2</td><td>2019-04-01 19:11:06</td><td>test9</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>1218测试</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>ccc</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>ceshi111</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>fengyu</td></tr><tr><td>8</td><td>2019-04-02 19:17:31</td><td>k k k k k k k</td></tr></tbody></table><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>从上面的结果看来，需求已实现。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文咱们使用mysql实现开窗函数row_number() over (partition by xxx,xxx order by xxx)，废话不多说，直接开干&lt;/p&gt;
&lt;h5 id=&quot;准备数据&quot;&gt;&lt;a href=&quot;#准备数据&quot; class=&quot;headerlink&quot; title=&quot;准备数据&quot;&gt;&lt;/a&gt;准备数据&lt;/h5&gt; &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;select * from test_biz_policy_policy;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;platform_id（平台id）&lt;/th&gt;
&lt;th&gt;publish_time（政策发布时间）&lt;/th&gt;
&lt;th&gt;policy_name（政策名称）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 15:11:06&lt;/td&gt;
&lt;td&gt;test0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 19:11:06&lt;/td&gt;
&lt;td&gt;test9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 19:11:06&lt;/td&gt;
&lt;td&gt;test8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 18:11:06&lt;/td&gt;
&lt;td&gt;test7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 15:11:06&lt;/td&gt;
&lt;td&gt;test1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 15:11:06&lt;/td&gt;
&lt;td&gt;test2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 16:11:06&lt;/td&gt;
&lt;td&gt;test3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 16:11:06&lt;/td&gt;
&lt;td&gt;test4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 16:11:06&lt;/td&gt;
&lt;td&gt;test5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2019-04-01 17:11:06&lt;/td&gt;
&lt;td&gt;test6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;fengyu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;新建政策1111111&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;1218测试&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;xxx&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;ccc&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;测试114&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;测试mmm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;k k k k k k k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;k k k k k k k明明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2019-04-02 19:17:31&lt;/td&gt;
&lt;td&gt;ceshi111&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h5&gt;&lt;p&gt;简而言之，就是以「平台id」,「政策发布时间」分组，根据「政策名称」进行排序，取政策前三名。&lt;br&gt;
    
    </summary>
    
      <category term="Mysql" scheme="https://www.gofunink.com/categories/Mysql/"/>
    
      <category term="Hive" scheme="https://www.gofunink.com/categories/Mysql/Hive/"/>
    
    
      <category term="Hive" scheme="https://www.gofunink.com/tags/Hive/"/>
    
      <category term="Mysql" scheme="https://www.gofunink.com/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Lateral View和Explode用法简介</title>
    <link href="https://www.gofunink.com/2019/04/02/Lateral%20View%E5%92%8CExplode%E7%94%A8%E6%B3%95%E7%AE%80%E4%BB%8B/"/>
    <id>https://www.gofunink.com/2019/04/02/Lateral View和Explode用法简介/</id>
    <published>2019-04-02T08:40:00.000Z</published>
    <updated>2019-04-02T08:40:34.298Z</updated>
    
    <content type="html"><![CDATA[<p>一、Explode用法</p><ul><li>hive wiki对于expolde的解释如下：</li></ul><blockquote><p>explode() takes in an array (or a map) as an input and outputs the elements of the array (map) as separate rows. UDTFs can be used in the SELECT expression list and as a part of LATERAL VIEW.</p></blockquote><blockquote><p>explode（）接受一个数组（或一个map）作为输入，并将数组元素（map）作为单独的行输出。 UDTF可以在SELECT表达式列表中使用，也可以作为LATERAL VIEW的一部分使用。</p></blockquote><p>使用如下图：</p><ul><li>将Map作为输入端</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/8901440-69f52c3041390f40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="map作为输入端"></p><ul><li>将ArrayList作为输入端:</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/8901440-038b8283ebd0eed6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="array作为输入端"></p><a id="more"></a><p>二、Lateral View用法</p><blockquote><p>lateral view的意义是配合explode（或者其他的UDTF），一个语句生成把单行数据拆解成多行后的数据结果集。</p></blockquote><p>首先准备一张表test，test表的数据结构如下</p><p><img src="https://upload-images.jianshu.io/upload_images/8901440-1f6bca5e063af010.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="test表结构"></p><h5 id="利用-lateral-view-explode-结合map的使用方式和结果如下："><a href="#利用-lateral-view-explode-结合map的使用方式和结果如下：" class="headerlink" title="利用 lateral view explode 结合map的使用方式和结果如下："></a>利用 lateral view explode 结合map的使用方式和结果如下：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    t.cola</span><br><span class="line">    ,t.indexa</span><br><span class="line">    ,tt.class_id</span><br><span class="line">    ,tt.score</span><br><span class="line">from test t</span><br><span class="line">LATERAL VIEW explode(map(&apos;1&apos;,100,&apos;2&apos;,200)) tt as class_id ,score</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>输出结果:</p><p><img src="https://upload-images.jianshu.io/upload_images/8901440-d55985e7a712923f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="结果"></p><p>结果注解：</p><p> test本身只有4条记录，  explode(map(‘1’,100,’2’,200)) 本身只有2条记录， </p><p>上述sql的原理实质上是对2个结果集做了笛卡尔积。</p><p>实现形式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line"></span><br><span class="line">    t1.column1</span><br><span class="line"></span><br><span class="line">    ,t1.column2</span><br><span class="line"></span><br><span class="line">    ,…</span><br><span class="line"></span><br><span class="line">    ,t2.column1</span><br><span class="line"></span><br><span class="line">    ,t2.column2 </span><br><span class="line"></span><br><span class="line">from tablea t1 </span><br><span class="line"></span><br><span class="line">lateral view explode(…) t2 as column1,column2</span><br><span class="line"></span><br><span class="line">;</span><br></pre></td></tr></table></figure></p><h5 id="利用-lateral-view-explode-结合array的使用方式和结果如下："><a href="#利用-lateral-view-explode-结合array的使用方式和结果如下：" class="headerlink" title="利用 lateral view explode 结合array的使用方式和结果如下："></a>利用 lateral view explode 结合array的使用方式和结果如下：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line"></span><br><span class="line">    t.cola</span><br><span class="line"></span><br><span class="line">    ,t.indexa</span><br><span class="line"></span><br><span class="line">    ,tt.class_id</span><br><span class="line"></span><br><span class="line">from test t</span><br><span class="line"></span><br><span class="line">lateral view explode(array(1,100)) tt as class_id</span><br><span class="line"></span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>输出如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/8901440-ed4067a7807e05ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ArrayList端结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一、Explode用法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hive wiki对于expolde的解释如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;explode() takes in an array (or a map) as an input and outputs the elements of the array (map) as separate rows. UDTFs can be used in the SELECT expression list and as a part of LATERAL VIEW.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;explode（）接受一个数组（或一个map）作为输入，并将数组元素（map）作为单独的行输出。 UDTF可以在SELECT表达式列表中使用，也可以作为LATERAL VIEW的一部分使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用如下图：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将Map作为输入端&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/8901440-69f52c3041390f40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;map作为输入端&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将ArrayList作为输入端:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/8901440-038b8283ebd0eed6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;array作为输入端&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://www.gofunink.com/categories/Hive/"/>
    
    
      <category term="Hive函数" scheme="https://www.gofunink.com/tags/Hive%E5%87%BD%E6%95%B0/"/>
    
      <category term="Explode" scheme="https://www.gofunink.com/tags/Explode/"/>
    
      <category term="Lateral View" scheme="https://www.gofunink.com/tags/Lateral-View/"/>
    
  </entry>
  
  <entry>
    <title>Linux定时任务使用</title>
    <link href="https://www.gofunink.com/2019/03/20/Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E4%BD%BF%E7%94%A8/"/>
    <id>https://www.gofunink.com/2019/03/20/Linux定时任务使用/</id>
    <published>2019-03-20T06:36:00.000Z</published>
    <updated>2019-03-22T07:22:17.180Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.---------------- minute (0 - 59) </span><br><span class="line">|  .------------- hour (0 - 23)</span><br><span class="line">|  |  .---------- day of month (1 - 31)</span><br><span class="line">|  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ... </span><br><span class="line">|  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7)  OR sun,mon,tue,wed,thu,fri,sat </span><br><span class="line">|  |  |  |  |</span><br><span class="line">*  *  *  *  *  command to be executed</span><br></pre></td></tr></table></figure><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">minute：代表一小时内的第几分,范围 0-59。</span><br><span class="line">hour：代表一天中的第几小时,范围 0-23。</span><br><span class="line">mday：代表一个月中的第几天,范围 1-31。</span><br><span class="line">month：代表一年中第几个月,范围 1-12。</span><br><span class="line">wday：代表星期几,范围 0-7 (0及7都是星期天)。</span><br><span class="line">who：要使用什么身份执行该指令,当您使用 crontab -e 时,不必加此字段。</span><br><span class="line">command：所要执行的指令。</span><br></pre></td></tr></table></figure><a id="more"></a><p>一般格式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* * * * *  who(用户)  command(命令)</span><br></pre></td></tr></table></figure></p><p>下面介绍创建定时任务的2种方法：</p><ul><li><p>方法一：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">crontab -e 其中 root代表用户 可不写</span><br><span class="line"></span><br><span class="line">* * * * *   root   /xx/xx/xx/xxx.sh</span><br></pre></td></tr></table></figure></li><li><p>方法二：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在/etc/cron.d/目录下创建 testCrontab 的文件</span><br><span class="line"></span><br><span class="line">touch testCrontab</span><br><span class="line"></span><br><span class="line">文件中编辑如下,其中 root代表用户 是要写的</span><br><span class="line"></span><br><span class="line">* * * * *  root  /xx/xx/xx/xxx.sh</span><br></pre></td></tr></table></figure></li></ul><p>下面列举一些例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 每天早上6点 </span><br><span class="line">0 6 * * * echo &quot;Good morning.&quot; &gt;&gt; /tmp/test.txt //注意单纯echo,从屏幕上看不到任何输出,因为cron把任何输出都email到root的信箱了。</span><br><span class="line"></span><br><span class="line"># 每两个小时 </span><br><span class="line">0 */2 * * * echo &quot;Have a break now.&quot; &gt;&gt; /tmp/test.txt  </span><br><span class="line"></span><br><span class="line"># 晚上11点到早上8点之间每两个小时和早上八点 </span><br><span class="line">0 23-7/2,8 * * * echo &quot;Have a good dream&quot; &gt;&gt; /tmp/test.txt</span><br><span class="line"></span><br><span class="line"># 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 </span><br><span class="line">0 11 4 * 1-3 command line</span><br><span class="line"></span><br><span class="line"># 1月1日早上4点 </span><br><span class="line">0 4 1 1 * command line SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root //如果出现错误,或者有数据输出,数据作为邮件发给这个帐号 HOME=/ </span><br><span class="line"></span><br><span class="line"># 每小时（第一分钟）执行/etc/cron.hourly内的脚本</span><br><span class="line">01 * * * * root run-parts /etc/cron.hourly</span><br><span class="line"></span><br><span class="line"># 每天（凌晨4：02）执行/etc/cron.daily内的脚本</span><br><span class="line">02 4 * * * root run-parts /etc/cron.daily </span><br><span class="line"></span><br><span class="line"># 每星期（周日凌晨4：22）执行/etc/cron.weekly内的脚本</span><br><span class="line">22 4 * * 0 root run-parts /etc/cron.weekly </span><br><span class="line"></span><br><span class="line"># 每月（1号凌晨4：42）去执行/etc/cron.monthly内的脚本 </span><br><span class="line">42 4 1 * * root run-parts /etc/cron.monthly </span><br><span class="line"></span><br><span class="line"># 注意:  &quot;run-parts&quot;这个参数了,如果去掉这个参数的话,后面就可以写要运行的某个脚本名,而不是文件夹名。 　 </span><br><span class="line"></span><br><span class="line"># 每天的下午4点、5点、6点的5 min、15 min、25 min、35 min、45 min、55 min时执行命令。 </span><br><span class="line">5,15,25,35,45,55 16,17,18 * * * command line</span><br><span class="line"></span><br><span class="line"># 每周一,三,五的下午3：00系统进入维护状态,重新启动系统。</span><br><span class="line">00 15 * * 1,3,5 shutdown -r +5</span><br><span class="line"></span><br><span class="line"># 每小时的10分,40分执行用户目录下的innd/bbslin这个指令： </span><br><span class="line">10,40 * * * * innd/bbslink </span><br><span class="line"></span><br><span class="line"># 每小时的1分执行用户目录下的bin/account这个指令： </span><br><span class="line">1 * * * * bin/account</span><br><span class="line"></span><br><span class="line"># 每天早晨三点二十分执行用户目录下如下所示的两个指令（每个指令以;分隔）： </span><br><span class="line">20 3 * * * （/bin/rm -f expire.ls logins.bad;bin/expire$#@62;expire.1st）</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;.---------------- minute (0 - 59) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|  .------------- hour (0 - 23)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|  |  .---------- day of month (1 - 31)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ... &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7)  OR sun,mon,tue,wed,thu,fri,sat &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|  |  |  |  |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*  *  *  *  *  command to be executed&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;minute：代表一小时内的第几分,范围 0-59。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hour：代表一天中的第几小时,范围 0-23。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mday：代表一个月中的第几天,范围 1-31。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;month：代表一年中第几个月,范围 1-12。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wday：代表星期几,范围 0-7 (0及7都是星期天)。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;who：要使用什么身份执行该指令,当您使用 crontab -e 时,不必加此字段。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;command：所要执行的指令。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://www.gofunink.com/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://www.gofunink.com/tags/Linux/"/>
    
      <category term="定时任务" scheme="https://www.gofunink.com/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>spark-submit脚本</title>
    <link href="https://www.gofunink.com/2019/03/20/spark-submit%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.gofunink.com/2019/03/20/spark-submit脚本/</id>
    <published>2019-03-20T04:06:00.000Z</published>
    <updated>2019-03-22T07:34:47.559Z</updated>
    
    <content type="html"><![CDATA[<pre><code>此spark-submit脚本可以配合定时任务，定时任务做定时5分钟（时间随你定，建议大于1分钟），用于监控spark实时任务，若spark实时任务挂掉，5分钟后会重新启动</code></pre><p>spark-submit脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"> count=`ps -ef | grep totalUriStreaming | grep -v grep | wc -l` </span><br><span class="line"> kinit -kt /root/hdfs.keytab hdfs/p37.awifi.com@AWIFI.COM  #此为kebros安全认证，若集群中没有kebros安全认证则不需要</span><br><span class="line"> if [ $count == 0 ]; then      </span><br><span class="line">     echo &quot;Start totalLogUriNums ...&quot;      </span><br><span class="line">     nohup spark-submit \</span><br><span class="line">     --class com.awifi.bigdata.syslog.totalLogUriNums.totalUriStreaming \</span><br><span class="line">     --master yarn \</span><br><span class="line">     --driver-memory 2G \</span><br><span class="line">     --executor-memory 4G \</span><br><span class="line">     --deploy-mode client \</span><br><span class="line">     --num-executors 12 \</span><br><span class="line">     --executor-cores 2 \</span><br><span class="line">     --jars /opt/gofunTest/jars/commons-pool2-2.0.jar,/opt/gofunTest/jars/jedis-2.8.1.jar,/opt/gofunTest/jars/fastjson-1.2.30.jar,/opt/gofunTest/jars/mysql-connector-java-5.1.41-bin.jar \</span><br><span class="line">     /opt/gofunTest/totalUriNums/sparkAnalysis.jar &gt; /opt/gofunTest/totalUriNums/totalUriNums.out 2&gt;&amp;1 &amp; </span><br><span class="line"> fi</span><br></pre></td></tr></table></figure></p><p>定时任务：(可以看我另一篇关于定时任务的博客)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/5 * * * * root /xxx/xxx/xxx/spark-submit.sh</span><br></pre></td></tr></table></figure></p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;此spark-submit脚本可以配合定时任务，定时任务做定时5分钟（时间随你定，建议大于1分钟），用于监控spark实时任务，若spark实时任务挂掉，5分钟后会重新启动
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;spark-submit脚本：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;#!/bin/bash&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; count=`ps -ef | grep totalUriStreaming | grep -v grep | wc -l` &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; kinit -kt /root/hdfs.keytab hdfs/p37.awifi.com@AWIFI.COM  #此为kebros安全认证，若集群中没有kebros安全认证则不需要&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; if [ $count == 0 ]; then      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     echo &amp;quot;Start totalLogUriNums ...&amp;quot;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     nohup spark-submit \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --class com.awifi.bigdata.syslog.totalLogUriNums.totalUriStreaming \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --master yarn \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --driver-memory 2G \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --executor-memory 4G \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --deploy-mode client \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --num-executors 12 \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --executor-cores 2 \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     --jars /opt/gofunTest/jars/commons-pool2-2.0.jar,/opt/gofunTest/jars/jedis-2.8.1.jar,/opt/gofunTest/jars/fastjson-1.2.30.jar,/opt/gofunTest/jars/mysql-connector-java-5.1.41-bin.jar \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     /opt/gofunTest/totalUriNums/sparkAnalysis.jar &amp;gt; /opt/gofunTest/totalUriNums/totalUriNums.out 2&amp;gt;&amp;amp;1 &amp;amp; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; fi&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;定时任务：(可以看我另一篇关于定时任务的博客)&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;*/5 * * * * root /xxx/xxx/xxx/spark-submit.sh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.gofunink.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://www.gofunink.com/tags/Spark/"/>
    
      <category term="spark-submit" scheme="https://www.gofunink.com/tags/spark-submit/"/>
    
  </entry>
  
  <entry>
    <title>CM集群中修改spark应用内存</title>
    <link href="https://www.gofunink.com/2019/03/20/CM%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BF%AE%E6%94%B9spark%E5%BA%94%E7%94%A8%E5%86%85%E5%AD%98/"/>
    <id>https://www.gofunink.com/2019/03/20/CM集群中修改spark应用内存/</id>
    <published>2019-03-20T03:42:00.000Z</published>
    <updated>2019-03-20T03:44:43.608Z</updated>
    
    <content type="html"><![CDATA[<h5 id="工作中可能会遇到这种问题："><a href="#工作中可能会遇到这种问题：" class="headerlink" title="工作中可能会遇到这种问题："></a>工作中可能会遇到这种问题：</h5><h5 id="集群的spark工作内存太小，比如只有50个G，如果想让spark工作内存变成100个G，则需要在CM控制台修改以下两个参数"><a href="#集群的spark工作内存太小，比如只有50个G，如果想让spark工作内存变成100个G，则需要在CM控制台修改以下两个参数" class="headerlink" title="集群的spark工作内存太小，比如只有50个G，如果想让spark工作内存变成100个G，则需要在CM控制台修改以下两个参数"></a>集群的spark工作内存太小，比如只有50个G，如果想让spark工作内存变成100个G，则需要在CM控制台修改以下两个参数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yarn.nodemanager.resource.memory-mb</span><br><span class="line">yarn.nodemanager.resource.cpu-vcores</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;工作中可能会遇到这种问题：&quot;&gt;&lt;a href=&quot;#工作中可能会遇到这种问题：&quot; class=&quot;headerlink&quot; title=&quot;工作中可能会遇到这种问题：&quot;&gt;&lt;/a&gt;工作中可能会遇到这种问题：&lt;/h5&gt;&lt;h5 id=&quot;集群的spark工作内存太小，比如只有50
      
    
    </summary>
    
      <category term="Spark" scheme="https://www.gofunink.com/categories/Spark/"/>
    
      <category term="CM" scheme="https://www.gofunink.com/categories/Spark/CM/"/>
    
    
      <category term="Spark" scheme="https://www.gofunink.com/tags/Spark/"/>
    
      <category term="CM" scheme="https://www.gofunink.com/tags/CM/"/>
    
  </entry>
  
  <entry>
    <title>SparkRDD转DataFrame的两种方式</title>
    <link href="https://www.gofunink.com/2019/03/20/SparkRDD%E8%BD%ACDataFrame%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
    <id>https://www.gofunink.com/2019/03/20/SparkRDD转DataFrame的两种方式/</id>
    <published>2019-03-20T03:26:00.000Z</published>
    <updated>2019-03-22T07:34:36.923Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SparkRDD转DataFrame-映射的方式"><a href="#SparkRDD转DataFrame-映射的方式" class="headerlink" title="SparkRDD转DataFrame 映射的方式"></a>SparkRDD转DataFrame 映射的方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">package com.gofun.sparkSql</span><br><span class="line"></span><br><span class="line">import org.apache.log4j.&#123;Level, Logger&#125;</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line">import org.apache.spark.sql.SQLContext</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * Create by IntelliJ IDEA.</span><br><span class="line">  * Author gofun</span><br><span class="line">  * 2017/10/10 20:18</span><br><span class="line">  */</span><br><span class="line">object RDD2DataFrameReflection &#123;</span><br><span class="line">  Logger.getLogger(&quot;org.apache.spark&quot;).setLevel(Level.WARN)</span><br><span class="line">  Logger.getLogger(&quot;org.apache.eclipse.jetty.server&quot;).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    rdd2DataFrame()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //rdd与dataframe转换</span><br><span class="line">  //在scala中使用反射方式，进行RDD到DataFrame转换，需要手动导入</span><br><span class="line">  def rdd2DataFrame(): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(&quot;rdd2DataFrame&quot;).setMaster(&quot;local[2]&quot;)</span><br><span class="line">    conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;192.168.157.200:2181&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    val sqlContext = new SQLContext(sc)</span><br><span class="line">    //    System.setProperty(&quot;hadoop.home.dir&quot;, &quot;E:\\hadoop-2.5.0-cdh5.3.6&quot;)</span><br><span class="line">    val lines = sc.textFile(&quot;hdfs://192.xxx.xxx.200:8020/test/student.txt&quot;)</span><br><span class="line">    val students = lines.map(_.split(&quot;\t&quot;))</span><br><span class="line">      .map &#123; line =&gt;</span><br><span class="line">        Student(line(0).trim().toInt, line(1).trim())</span><br><span class="line">      &#125;</span><br><span class="line">    val studentDF = sqlContext.createDataFrame(students)</span><br><span class="line">    studentDF.registerTempTable(&quot;studentTable&quot;)</span><br><span class="line">    val df = sqlContext.sql(&quot;select * from studentTable&quot;)</span><br><span class="line">    df.rdd.collect().foreach(println)</span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case class Student(id: Int, name: String)</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="SparkRDD转DataFrame-构造元数据的方式"><a href="#SparkRDD转DataFrame-构造元数据的方式" class="headerlink" title="SparkRDD转DataFrame 构造元数据的方式"></a>SparkRDD转DataFrame 构造元数据的方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">package com.gofun.sparkSql</span><br><span class="line"></span><br><span class="line">import org.apache.log4j.&#123;Level, Logger&#125;</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line">import org.apache.spark.sql.&#123;Row, RowFactory, SQLContext&#125;</span><br><span class="line">import org.apache.spark.sql.types._</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * Create by IntelliJ IDEA.</span><br><span class="line">  * Author gofun</span><br><span class="line">  * 2017/10/10 20:19</span><br><span class="line">  */</span><br><span class="line">object RDD2DataFrameProgrammatically extends App &#123;</span><br><span class="line">  Logger.getLogger(&quot;org.apache.spark&quot;).setLevel(Level.WARN)</span><br><span class="line">  Logger.getLogger(&quot;org.apache.eclipse.jetty.server&quot;).setLevel(Level.OFF)</span><br><span class="line"></span><br><span class="line">  override def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    rdd2DataFrame()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //构造元数据的方式加载数据将rdd转换为dataFrame</span><br><span class="line">  def rdd2DataFrame(): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(&quot;RDD2DataFrameProgrammatically&quot;).setMaster(&quot;local[2]&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    val sqlContext = new SQLContext(sc)</span><br><span class="line">    val lines = sc.textFile(&quot;hdfs://192.xxx.xx.200:8020/test/student.txt&quot;)</span><br><span class="line">    val studentRdd = lines.map(_.split(&quot; &quot;)).map(line =&gt; RowFactory.create(Integer.valueOf(line(0)), String.valueOf(line(1)), Integer.valueOf(line(2))))</span><br><span class="line">    val fields = new scala.collection.mutable.ArrayBuffer[StructField]()</span><br><span class="line">    fields += DataTypes.createStructField(&quot;id&quot;, DataTypes.IntegerType, true)</span><br><span class="line">    fields += DataTypes.createStructField(&quot;name&quot;, DataTypes.StringType, true)</span><br><span class="line">    fields += DataTypes.createStructField(&quot;age&quot;, DataTypes.IntegerType, true)</span><br><span class="line">    val structType = DataTypes.createStructType(fields.toArray)</span><br><span class="line">    val studentDF = sqlContext.createDataFrame(studentRdd, structType)</span><br><span class="line">    studentDF.registerTempTable(&quot;student&quot;)</span><br><span class="line">    val df = sqlContext.sql(&quot;select name from student&quot;)</span><br><span class="line">    df.rdd.collect().foreach(println)</span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def rdd2DataFrame2(): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(&quot;RDD2DataFrameProgrammatically&quot;).setMaster(&quot;local[2]&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    val sqlContext = new SQLContext(sc)</span><br><span class="line">    val lines = sc.textFile(&quot;hdfs://192.168.64.200:8020/test/student.txt&quot;, 1)</span><br><span class="line">    val studentRDD = lines.map(line =&gt; Row(line.split(&quot; &quot;)(0).toInt, line.split(&quot; &quot;)(1), line.split(&quot; &quot;)(2).toInt))</span><br><span class="line">    val structType = StructType(Array(StructField(&quot;id&quot;, IntegerType, true), StructField(&quot;name&quot;, StringType, true), StructField(&quot;age&quot;, IntegerType, true)))</span><br><span class="line">    val studentDF = sqlContext.createDataFrame(studentRDD, structType)</span><br><span class="line">    studentDF.registerTempTable(&quot;student&quot;)</span><br><span class="line">    val df = sqlContext.sql(&quot;select name,age from student&quot;)</span><br><span class="line">    df.rdd.foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SparkRDD转DataFrame-映射的方式&quot;&gt;&lt;a href=&quot;#SparkRDD转DataFrame-映射的方式&quot; class=&quot;headerlink&quot; title=&quot;SparkRDD转DataFrame 映射的方式&quot;&gt;&lt;/a&gt;SparkRDD转DataFrame 映射的方式&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;package com.gofun.sparkSql&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import org.apache.log4j.&amp;#123;Level, Logger&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import org.apache.spark.&amp;#123;SparkConf, SparkContext&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;import org.apache.spark.sql.SQLContext&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/**&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  * Create by IntelliJ IDEA.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  * Author gofun&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  * 2017/10/10 20:18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;object RDD2DataFrameReflection &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Logger.getLogger(&amp;quot;org.apache.spark&amp;quot;).setLevel(Level.WARN)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  Logger.getLogger(&amp;quot;org.apache.eclipse.jetty.server&amp;quot;).setLevel(Level.OFF)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  def main(args: Array[String]): Unit = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rdd2DataFrame()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  //rdd与dataframe转换&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  //在scala中使用反射方式，进行RDD到DataFrame转换，需要手动导入&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  def rdd2DataFrame(): Unit = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val conf = new SparkConf().setAppName(&amp;quot;rdd2DataFrame&amp;quot;).setMaster(&amp;quot;local[2]&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    conf.set(&amp;quot;hbase.zookeeper.quorum&amp;quot;, &amp;quot;192.168.157.200:2181&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val sc = new SparkContext(conf)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val sqlContext = new SQLContext(sc)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    //    System.setProperty(&amp;quot;hadoop.home.dir&amp;quot;, &amp;quot;E:\\hadoop-2.5.0-cdh5.3.6&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val lines = sc.textFile(&amp;quot;hdfs://192.xxx.xxx.200:8020/test/student.txt&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val students = lines.map(_.split(&amp;quot;\t&amp;quot;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      .map &amp;#123; line =&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        Student(line(0).trim().toInt, line(1).trim())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val studentDF = sqlContext.createDataFrame(students)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    studentDF.registerTempTable(&amp;quot;studentTable&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val df = sqlContext.sql(&amp;quot;select * from studentTable&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    df.rdd.collect().foreach(println)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    sc.stop()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;case class Student(id: Int, name: String)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://www.gofunink.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://www.gofunink.com/tags/Spark/"/>
    
      <category term="SparkRDD" scheme="https://www.gofunink.com/tags/SparkRDD/"/>
    
      <category term="DataFrame" scheme="https://www.gofunink.com/tags/DataFrame/"/>
    
  </entry>
  
  <entry>
    <title>Hive时间函数</title>
    <link href="https://www.gofunink.com/2019/03/20/Hive%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0/"/>
    <id>https://www.gofunink.com/2019/03/20/Hive时间函数/</id>
    <published>2019-03-20T02:45:00.000Z</published>
    <updated>2019-03-22T07:27:27.935Z</updated>
    
    <content type="html"><![CDATA[<!-- <div style="-webkit-box-shadow: 0 0 14px rgba(202,203,203,1);-moz-box-shadow: 0 0 14px rgba(202,203,204,1);background: #fff;padding: 25px;margin-bottom: 100px;"> --><h5 id="当前时间"><a href="#当前时间" class="headerlink" title="当前时间"></a>当前时间</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">语法: select from_unixtime(unix_timestamp(),&apos;yyyy-MM-dd HH:mm:ss’)</span><br><span class="line"></span><br><span class="line">返回值: string</span><br><span class="line"></span><br><span class="line">hive&gt; select from_unixtime(1323308943,’yyyyMMdd’) from dual;</span><br><span class="line">2019-03-19 17:37:03</span><br></pre></td></tr></table></figure><h5 id="UNIX时间戳转日期函数-from-unixtime"><a href="#UNIX时间戳转日期函数-from-unixtime" class="headerlink" title="UNIX时间戳转日期函数: from_unixtime"></a>UNIX时间戳转日期函数: from_unixtime</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: from_unixtime(bigint unixtime[, string format])</span><br><span class="line"> </span><br><span class="line">返回值: string</span><br><span class="line">说明: 转化UNIX时间戳（从1970-01-01 00:00:00 UTC到指定时间的秒数）到当前时区的时间格式</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select from_unixtime(1323308943,’yyyyMMdd’) from dual;</span><br><span class="line">20111208</span><br></pre></td></tr></table></figure><h5 id="获取当前UNIX时间戳函数-unix-timestamp"><a href="#获取当前UNIX时间戳函数-unix-timestamp" class="headerlink" title="获取当前UNIX时间戳函数: unix_timestamp"></a>获取当前UNIX时间戳函数: unix_timestamp</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: unix_timestamp()</span><br><span class="line"> </span><br><span class="line">返回值: bigint</span><br><span class="line">说明: 获得当前时区的UNIX时间戳</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select unix_timestamp() from dual;</span><br><span class="line">1323309615</span><br></pre></td></tr></table></figure><h5 id="日期转UNIX时间戳函数-unix-timestamp"><a href="#日期转UNIX时间戳函数-unix-timestamp" class="headerlink" title="日期转UNIX时间戳函数: unix_timestamp"></a>日期转UNIX时间戳函数: unix_timestamp</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: unix_timestamp(string date)</span><br><span class="line"> </span><br><span class="line">返回值: bigint</span><br><span class="line">说明: 转换格式为“yyyy-MM-dd HH:mm:ss“的日期到UNIX时间戳。如果转化失败，则返回0。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select unix_timestamp(’2011-12-07 13:01:03′) from dual;</span><br><span class="line">1323234063</span><br></pre></td></tr></table></figure><a id="more"></a><h5 id="指定格式日期转UNIX时间戳函数-unix-timestamp"><a href="#指定格式日期转UNIX时间戳函数-unix-timestamp" class="headerlink" title="指定格式日期转UNIX时间戳函数: unix_timestamp"></a>指定格式日期转UNIX时间戳函数: unix_timestamp</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: unix_timestamp(string date, string pattern)</span><br><span class="line"> </span><br><span class="line">返回值: bigint</span><br><span class="line">说明: 转换pattern格式的日期到UNIX时间戳。如果转化失败，则返回0。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select unix_timestamp(’20111207 13:01:03′,’yyyyMMdd HH:mm:ss’) from dual;</span><br><span class="line">1323234063</span><br></pre></td></tr></table></figure><h5 id="日期时间转日期函数-to-date"><a href="#日期时间转日期函数-to-date" class="headerlink" title="日期时间转日期函数: to_date"></a>日期时间转日期函数: to_date</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: to_date(string timestamp)</span><br><span class="line"> </span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回日期时间字段中的日期部分。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select to_date(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">2011-12-08</span><br></pre></td></tr></table></figure><h5 id="日期转年函数-year"><a href="#日期转年函数-year" class="headerlink" title="日期转年函数: year"></a>日期转年函数: year</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: year(string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期中的年。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select year(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">2011</span><br><span class="line">hive&gt; select year(’2012-12-08′) from dual;</span><br><span class="line">2012</span><br></pre></td></tr></table></figure><h5 id="日期转月函数-month"><a href="#日期转月函数-month" class="headerlink" title="日期转月函数: month"></a>日期转月函数: month</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: month (string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期中的月份。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select month(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">12</span><br><span class="line">hive&gt; select month(’2011-08-08′) from dual;</span><br><span class="line">8</span><br></pre></td></tr></table></figure><h5 id="日期转天函数-day"><a href="#日期转天函数-day" class="headerlink" title="日期转天函数: day"></a>日期转天函数: day</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">语法: day (string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期中的天。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select day(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">8</span><br><span class="line">hive&gt; select day(’2011-12-24′) from dual;</span><br><span class="line">24</span><br></pre></td></tr></table></figure><h5 id="日期转小时函数-hour"><a href="#日期转小时函数-hour" class="headerlink" title="日期转小时函数: hour"></a>日期转小时函数: hour</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: hour (string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期中的小时。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select hour(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">10</span><br></pre></td></tr></table></figure><h5 id="日期转分钟函数-minute"><a href="#日期转分钟函数-minute" class="headerlink" title="日期转分钟函数: minute"></a>日期转分钟函数: minute</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: minute (string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期中的分钟。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select minute(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">3</span><br></pre></td></tr></table></figure><h5 id="日期转秒函数-second"><a href="#日期转秒函数-second" class="headerlink" title="日期转秒函数: second"></a>日期转秒函数: second</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: second (string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期中的秒。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select second(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h5 id="日期转周函数-weekofyear"><a href="#日期转周函数-weekofyear" class="headerlink" title="日期转周函数: weekofyear"></a>日期转周函数: weekofyear</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: weekofyear (string date)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回日期在当前的周数。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select weekofyear(’2011-12-08 10:03:01′) from dual;</span><br><span class="line">49</span><br></pre></td></tr></table></figure><h5 id="日期比较函数-datediff"><a href="#日期比较函数-datediff" class="headerlink" title="日期比较函数: datediff"></a>日期比较函数: datediff</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: datediff(string enddate, string startdate)</span><br><span class="line"> </span><br><span class="line">返回值: int</span><br><span class="line">说明: 返回结束日期减去开始日期的天数。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select datediff(’2012-12-08′,’2012-05-09′) from dual;</span><br><span class="line">213</span><br></pre></td></tr></table></figure><h5 id="日期增加函数-date-add"><a href="#日期增加函数-date-add" class="headerlink" title="日期增加函数: date_add"></a>日期增加函数: date_add</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: date_add(string startdate, int days)</span><br><span class="line"> </span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回开始日期startdate增加days天后的日期。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select date_add(’2012-12-08′,10) from dual;</span><br><span class="line">2012-12-18</span><br></pre></td></tr></table></figure><h5 id="日期减少函数-date-sub"><a href="#日期减少函数-date-sub" class="headerlink" title="日期减少函数: date_sub"></a>日期减少函数: date_sub</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">语法: date_sub (string startdate, int days)</span><br><span class="line"> </span><br><span class="line">返回值: string</span><br><span class="line">说明: 返回开始日期startdate减少days天后的日期。</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select date_sub(’2012-12-08′,10) from dual;</span><br><span class="line">2012-11-28</span><br></pre></td></tr></table></figure><h5 id="yyyyMMdd转成yyyy-MM-dd"><a href="#yyyyMMdd转成yyyy-MM-dd" class="headerlink" title="yyyyMMdd转成yyyy-MM-dd"></a>yyyyMMdd转成yyyy-MM-dd</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">方法一 语法: from_unixtime+ unix_timestamp</span><br><span class="line"></span><br><span class="line">返回值：string</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select from_unixtime(unix_timestamp(&apos;20171205&apos;,&apos;yyyymmdd&apos;),&apos;yyyy-mm-dd&apos;) from dual;</span><br><span class="line">2017-12-05</span><br><span class="line"></span><br><span class="line">方法二 语法: substr + concat</span><br><span class="line"></span><br><span class="line">返回值：string</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select concat(substr(&apos;20171205&apos;,1,4),&apos;-&apos;,substr(&apos;20171205&apos;,5,2),&apos;-&apos;,substr(&apos;20171205&apos;,7,2)) from dual;</span><br><span class="line">2017-12-05</span><br></pre></td></tr></table></figure><h5 id="yyyy-MM-dd转成yyyyMMdd"><a href="#yyyy-MM-dd转成yyyyMMdd" class="headerlink" title="yyyy-MM-dd转成yyyyMMdd"></a>yyyy-MM-dd转成yyyyMMdd</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">方法一 语法: from_unixtime+ unix_timestamp</span><br><span class="line"></span><br><span class="line">返回值：string</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select from_unixtime(unix_timestamp(&apos;2017-12-05&apos;,&apos;yyyy-mm-dd&apos;),&apos;yyyymmdd&apos;) from dual;</span><br><span class="line">20171205</span><br><span class="line"></span><br><span class="line">方法二 语法: substr + concat</span><br><span class="line"></span><br><span class="line">返回值：string</span><br><span class="line">举例：</span><br><span class="line">hive&gt; select concat(substr(&apos;2017-12-05&apos;,1,4),substr(&apos;2017-12-05&apos;,6,2),substr(&apos;2017-12-05&apos;,9,2)) from dual;</span><br><span class="line">20171205</span><br></pre></td></tr></table></figure><!-- </div> -->]]></content>
    
    <summary type="html">
    
      &lt;!-- &lt;div style=&quot;-webkit-box-shadow: 0 0 14px rgba(202,203,203,1);-moz-box-shadow: 0 0 14px rgba(202,203,204,1);
background: #fff;padding: 25px;margin-bottom: 100px;&quot;&gt; --&gt;
&lt;h5 id=&quot;当前时间&quot;&gt;&lt;a href=&quot;#当前时间&quot; class=&quot;headerlink&quot; title=&quot;当前时间&quot;&gt;&lt;/a&gt;当前时间&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;语法: select from_unixtime(unix_timestamp(),&amp;apos;yyyy-MM-dd HH:mm:ss’)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;返回值: string&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hive&amp;gt; select from_unixtime(1323308943,’yyyyMMdd’) from dual;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2019-03-19 17:37:03&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h5 id=&quot;UNIX时间戳转日期函数-from-unixtime&quot;&gt;&lt;a href=&quot;#UNIX时间戳转日期函数-from-unixtime&quot; class=&quot;headerlink&quot; title=&quot;UNIX时间戳转日期函数: from_unixtime&quot;&gt;&lt;/a&gt;UNIX时间戳转日期函数: from_unixtime&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;语法: from_unixtime(bigint unixtime[, string format])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;返回值: string&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;说明: 转化UNIX时间戳（从1970-01-01 00:00:00 UTC到指定时间的秒数）到当前时区的时间格式&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;举例：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hive&amp;gt; select from_unixtime(1323308943,’yyyyMMdd’) from dual;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20111208&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h5 id=&quot;获取当前UNIX时间戳函数-unix-timestamp&quot;&gt;&lt;a href=&quot;#获取当前UNIX时间戳函数-unix-timestamp&quot; class=&quot;headerlink&quot; title=&quot;获取当前UNIX时间戳函数: unix_timestamp&quot;&gt;&lt;/a&gt;获取当前UNIX时间戳函数: unix_timestamp&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;语法: unix_timestamp()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;返回值: bigint&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;说明: 获得当前时区的UNIX时间戳&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;举例：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hive&amp;gt; select unix_timestamp() from dual;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1323309615&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h5 id=&quot;日期转UNIX时间戳函数-unix-timestamp&quot;&gt;&lt;a href=&quot;#日期转UNIX时间戳函数-unix-timestamp&quot; class=&quot;headerlink&quot; title=&quot;日期转UNIX时间戳函数: unix_timestamp&quot;&gt;&lt;/a&gt;日期转UNIX时间戳函数: unix_timestamp&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;语法: unix_timestamp(string date)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;返回值: bigint&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;说明: 转换格式为“yyyy-MM-dd HH:mm:ss“的日期到UNIX时间戳。如果转化失败，则返回0。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;举例：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hive&amp;gt; select unix_timestamp(’2011-12-07 13:01:03′) from dual;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1323234063&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://www.gofunink.com/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://www.gofunink.com/tags/Hive/"/>
    
      <category term="时间函数" scheme="https://www.gofunink.com/tags/%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Mysql数据导出到Hbase</title>
    <link href="https://www.gofunink.com/2019/03/08/Mysql%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E5%88%B0Hbase/"/>
    <id>https://www.gofunink.com/2019/03/08/Mysql数据导出到Hbase/</id>
    <published>2019-03-08T09:14:58.000Z</published>
    <updated>2019-03-22T07:27:12.416Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Mysql表center_pub_merchant数据导出为center_pub_merchant.tsv</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h 172.xx.x.175 -P 3307 -uUSER -pPASSWORD -e &quot;SELECT concat(&apos;merchant:&apos;,id), parentId, id, cascade_label AS cascadeLabel, cascade_level AS cascadeLevel, account_id AS accountId, merchant_name AS merchantName,merchant_type AS merchantType,merchant_project AS merchantProject, full_name AS fullName, telephone, email, thumb, industry, user_id AS userId, province,city, county FROM center_pub_merchant&quot; awifi_dc &gt; /opt/gofunTest/center_pub_merchant.tsv</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put center_pub_merchant.tsv /tmp/center_pub_merchant.tsv</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,base_data:parentId,base_data:id,base_data:cascadeLabel,base_data:cascadeLevel,base_data:accountId,base_data:merchantName,base_data:merchantType,base_data:merchantProject,base_data:fullName,base_data:telephone,base_data:email,base_data:thumb,base_data:industry,base_data:userId,base_data:province,base_data:city,base_data:county tj_base_merchant /tmp/center_pub_merchant.tsv</span><br></pre></td></tr></table></figure><p><strong>Mysql表center_pub_device数据导出为center_pub_device.tsv</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h 172.XX.X.175 -P 3307 -uUSER -pPASSWORD -e &quot;SELECT concat(&apos;device:&apos;,d.device_id),d.province,d.city,d.county,e.entity_type as entityType,d.device_id as deviceId,d.project_id as projectId,d.belongto FROM center_pub_device d INNER JOIN center_pub_entity e ON d.OUT_ID = e.ID WHERE d.OUT_TYPE_ID = &apos;00&apos;&quot; awifi_dc &gt; /opt/gofunTest/center_pub_device.tsv</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put center_pub_device.tsv /tmp/center_pub_device.tsv</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,base_data:province,base_data:city,base_data:county,base_data:entityType,base_data:deviceId,base_data:projectId,base_data:belongto tj_base_device /tmp/center_pub_device.tsv</span><br></pre></td></tr></table></figure><a id="more"></a><p>注意：</p><ul><li>若Permission denied: user=hbase, access=WRITE, inode=”/user”:hdfs:supergroup:drwxr-xr-x<pre><code>修改 hadoop fs -chmod 777 /user</code></pre></li><li>若报min.user.id。。。的错<pre><code>找到这个文件/etc/hadoop/conf.cloudera.yarn/container-executor.cfgchmod 755 container-executor.cfg将 min.user.id=900改小          chmod 400 container-executor.cfg</code></pre></li><li>若报banned.users。。。的错<pre><code>chmod 755 container-executor.cfg则将banned.users=hdfs,yarn,mapred,bin中hdfs删掉          chmod 400 container-executor.cfg</code></pre></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Mysql表center_pub_merchant数据导出为center_pub_merchant.tsv&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql -h 172.xx.x.175 -P 3307 -uUSER -pPASSWORD -e &amp;quot;SELECT concat(&amp;apos;merchant:&amp;apos;,id), parentId, id, cascade_label AS cascadeLabel, cascade_level AS cascadeLevel, account_id AS accountId, merchant_name AS merchantName,merchant_type AS merchantType,merchant_project AS merchantProject, full_name AS fullName, telephone, email, thumb, industry, user_id AS userId, province,city, county FROM center_pub_merchant&amp;quot; awifi_dc &amp;gt; /opt/gofunTest/center_pub_merchant.tsv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfs -put center_pub_merchant.tsv /tmp/center_pub_merchant.tsv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,base_data:parentId,base_data:id,base_data:cascadeLabel,base_data:cascadeLevel,base_data:accountId,base_data:merchantName,base_data:merchantType,base_data:merchantProject,base_data:fullName,base_data:telephone,base_data:email,base_data:thumb,base_data:industry,base_data:userId,base_data:province,base_data:city,base_data:county tj_base_merchant /tmp/center_pub_merchant.tsv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Mysql表center_pub_device数据导出为center_pub_device.tsv&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql -h 172.XX.X.175 -P 3307 -uUSER -pPASSWORD -e &amp;quot;SELECT concat(&amp;apos;device:&amp;apos;,d.device_id),d.province,d.city,d.county,e.entity_type as entityType,d.device_id as deviceId,d.project_id as projectId,d.belongto FROM center_pub_device d INNER JOIN center_pub_entity e ON d.OUT_ID = e.ID WHERE d.OUT_TYPE_ID = &amp;apos;00&amp;apos;&amp;quot; awifi_dc &amp;gt; /opt/gofunTest/center_pub_device.tsv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hdfs dfs -put center_pub_device.tsv /tmp/center_pub_device.tsv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=HBASE_ROW_KEY,base_data:province,base_data:city,base_data:county,base_data:entityType,base_data:deviceId,base_data:projectId,base_data:belongto tj_base_device /tmp/center_pub_device.tsv&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Mysql" scheme="https://www.gofunink.com/categories/Mysql/"/>
    
      <category term="Hbase" scheme="https://www.gofunink.com/categories/Mysql/Hbase/"/>
    
    
      <category term="Mysql" scheme="https://www.gofunink.com/tags/Mysql/"/>
    
      <category term="Hbase" scheme="https://www.gofunink.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hive优化</title>
    <link href="https://www.gofunink.com/2019/03/07/Hive%E4%BC%98%E5%8C%96/"/>
    <id>https://www.gofunink.com/2019/03/07/Hive优化/</id>
    <published>2019-03-07T12:15:58.000Z</published>
    <updated>2019-03-22T07:26:11.229Z</updated>
    
    <content type="html"><![CDATA[<!-- <div style="-webkit-box-shadow: 0 0 14px rgba(202,203,203,1);-moz-box-shadow: 0 0 14px rgba(202,203,204,1);background: #fff;padding: 25px;margin-bottom: 100px;"> --><h1 id="HIVE的优化总结"><a href="#HIVE的优化总结" class="headerlink" title="HIVE的优化总结"></a>HIVE的优化总结</h1><p>Hive是将符合SQL语法的字符串解析生成可以在Hadoop上执行的MapReduce的工具。使用Hive尽量按照分布式计算的一些特点来设计sql，和传统关系型数据库有区别，</p><p>所以需要去掉原有关系型数据库下开发的一些固有思维。</p><p>基本原则：</p><p><strong>1、尽量尽早地过滤数据，减少每个阶段的数据量,对于分区表要加分区，同时只选择需要使用到的字段</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">select ... from A </span><br><span class="line"></span><br><span class="line">join B</span><br><span class="line"></span><br><span class="line">on A.key = B.key</span><br><span class="line"></span><br><span class="line">where A.userid&gt;10</span><br><span class="line"></span><br><span class="line">     and B.userid&lt;10</span><br><span class="line"></span><br><span class="line">     and A.dt=&apos;20120417&apos;</span><br><span class="line"></span><br><span class="line">     and B.dt=&apos;20120417&apos;;</span><br></pre></td></tr></table></figure></p><p>应该改写为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">select .... from </span><br><span class="line">  </span><br><span class="line">       (select .... from A</span><br><span class="line"></span><br><span class="line">        where dt=&apos;201200417&apos;</span><br><span class="line"></span><br><span class="line">        and userid&gt;10</span><br><span class="line"></span><br><span class="line">       ) a</span><br><span class="line"></span><br><span class="line">join </span><br><span class="line"></span><br><span class="line">      ( select .... from B</span><br><span class="line"></span><br><span class="line">       where dt=&apos;201200417&apos;</span><br><span class="line"></span><br><span class="line">       and userid &lt; 10   </span><br><span class="line"></span><br><span class="line">      ) b</span><br><span class="line"></span><br><span class="line">on a.key = b.key;</span><br></pre></td></tr></table></figure></p><a id="more"></a><p><strong>2、对历史库的计算经验  (这项是说根据不同的使用目的优化使用方法)</strong></p><pre><code>历史库计算和使用，分区</code></pre><p><strong>3、尽量原子化操作，尽量避免一个SQL包含复杂逻辑</strong></p><pre><code>可以使用中间表来完成复杂的逻辑   </code></pre><p><strong>4、jion操作   小表要注意放在join的左边（目前TCL里面很多都小表放在join的右边）。</strong></p><pre><code>否则会引起磁盘和内存的大量消耗</code></pre><p><strong>5、如果union all的部分个数大于2，或者每个union部分数据量大，应该拆成多个insert into 语句，实际测试过程中，执行时间能提升50%</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">insert overwite table tablename partition (dt= ....)</span><br><span class="line"></span><br><span class="line">select ..... from (</span><br><span class="line"></span><br><span class="line">                   select ... from A</span><br><span class="line"></span><br><span class="line">                   union all</span><br><span class="line"></span><br><span class="line">                   select ... from B</span><br><span class="line"></span><br><span class="line">                   union all</span><br><span class="line"></span><br><span class="line">                   select ... from C</span><br><span class="line"></span><br><span class="line">                               ) R</span><br><span class="line"></span><br><span class="line">where ...;</span><br></pre></td></tr></table></figure></p><p>可以改写为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">insert into table tablename partition (dt= ....)</span><br><span class="line"></span><br><span class="line">select .... from A</span><br><span class="line"></span><br><span class="line">WHERE ...;</span><br><span class="line"></span><br><span class="line">insert into table tablename partition (dt= ....)</span><br><span class="line"></span><br><span class="line">select .... from B</span><br><span class="line"></span><br><span class="line">WHERE ...;</span><br><span class="line"></span><br><span class="line">insert into table tablename partition (dt= ....)</span><br><span class="line"></span><br><span class="line">select .... from C</span><br><span class="line"></span><br><span class="line">WHERE ...;</span><br></pre></td></tr></table></figure></p><p><strong>6、写SQL要先了解数据本身的特点，如果有join ,group操作的话，要注意是否会有数据倾斜</strong></p><ul><li><p>如果出现数据倾斜，应当做如下处理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.reducers.max=200;</span><br><span class="line"></span><br><span class="line">set mapred.reduce.tasks= 200;                    ---增大Reduce个数</span><br><span class="line"></span><br><span class="line">set hive.groupby.mapaggr.checkinterval=100000;   --这个是group的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置</span><br><span class="line"></span><br><span class="line">set hive.groupby.skewindata=true;                --如果是group by过程出现倾斜 应该设置为true</span><br><span class="line"></span><br><span class="line">set hive.skewjoin.key=100000;                    --这个是join的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置</span><br><span class="line"></span><br><span class="line">set hive.optimize.skewjoin=true;                 --如果是join 过程出现倾斜 应该设置为true</span><br></pre></td></tr></table></figure><p>  (1)  启动一次job尽可能的多做事情，一个job能完成的事情,不要两个job来做</p><p>  通常来说前面的任务启动可以稍带一起做的事情就一起做了,以便后续的多个任务重用,与此紧密相连的是模型设计,好的模型特别重要.</p><p>  (2) 合理设置reduce个数</p><p>  reduce个数过少没有真正发挥hadoop并行计算的威力，但reduce个数过多，会造成大量小文件问题                        ，数据量、资源情况只有自己最清楚，找到个折衷点,</p><p>  (3) 使用hive.exec.parallel参数控制在同一个sql中的不同的job是否可以同时运行，提高作业的并发</p></li><li><p>让服务器尽量少做事情，走最优的路径，以资源消耗最少为目标</p><p>(1) 注意join的使用</p><pre><code>若其中有一个表很小使用map join，否则使用普通的reduce join，注意hive会将join前面的表数据装载内存,所以较小的一个表在较大的表之前,减少内存资源的消耗</code></pre><p>(2)注意小文件的问题</p><pre><code>在hive里有两种比较常见的处理办法第一是使用Combinefileinputformat，将多个小文件打包作为一个整体的inputsplit，减少map任务数set mapred.max.split.size=256000000;set mapred.min.split.size.per.node=256000000set  Mapred.min.split.size.per.rack=256000000set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat第二是设置hive参数，将额外启动一个MR Job打包小文件hive.merge.mapredfiles = false 是否合并 Reduce 输出文件，默认为 Falsehive.merge.size.per.task = 256*1000*1000 合并文件的大小</code></pre><p>  (3)注意数据倾斜</p><pre><code>在hive里比较常用的处理办法第一通过hive.groupby.skewindata=true控制生成两个MR Job,第一个MR Job Map的输出结果随机分配到reduce做次预汇总,减少某些key值条数过多某些key条数过小造成的数据倾斜问题第二通过hive.map.aggr = true(默认为true)在Map端做combiner,假如map各条数据基本上不一样, 聚合没什么意义，做combiner反而画蛇添足,hive里也考虑的比较周到通过参数hive.groupby.mapaggr.checkinterval = 100000 (默认)hive.map.aggr.hash.min.reduction=0.5(默认),预先取100000条数据聚合,如果聚合后的条数/100000&gt;0.5，则不再聚合</code></pre><p>(4)善用multi insert,union all</p><pre><code>multi insert适合基于同一个源表按照不同逻辑不同粒度处理插入不同表的场景，做到只需要扫描源表一次，job个数不变，减少源表扫描次数union all用好，可减少表的扫描次数，减少job的个数,通常预先按不同逻辑不同条件生成的查询union all后，再统一group by计算,不同表的union all相当于multiple inputs,同一个表的union all,相当map一次输出多条</code></pre><p>(5) 参数设置的调优</p><p>   集群参数种类繁多,举个例子比如</p><p>   可针对特定job设置特定参数,比如jvm重用,reduce copy线程数量设置(适合map较快，输出量较大)</p><p>   如果任务数多且小，比如在一分钟之内完成，减少task数量以减少任务初始化的消耗。可以通过配置JVM重用选项减少task的消耗</p></li></ul><p><strong>一、控制Hive中Map和reduce的数量</strong></p><pre><code>Hive中的sql查询会生成执行计划，执行计划以MapReduce的方式执行，那么结合数据和集群的大小，map和reduce的数量就会影响到sql执行的效率。除了要控制Hive生成的Job的数量，也要控制map和reduce的数量。</code></pre><p><strong>1、map的数量，通常情况下和split的大小有关系</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive中默认的hive.input.format是org.apache.hadoop.hive.ql.io.CombineHiveInputFormat，对于combineHiveInputFormat,它的输入的map数量由三个配置决定，</span><br><span class="line"></span><br><span class="line">mapred.min.split.size.per.node， 一个节点上split的至少的大小</span><br><span class="line"></span><br><span class="line">mapred.min.split.size.per.rack 一个交换机下split至少的大小</span><br><span class="line"></span><br><span class="line">mapred.max.split.size 一个split最大的大小</span><br></pre></td></tr></table></figure></p><p>它的主要思路是把输入目录下的大文件分成多个map的输入, 并合并小文件, 做为一个map的输入. 具体的原理是下述三步:</p><pre><code>a、根据输入目录下的每个文件,如果其长度超过mapred.max.split.size,以block为单位分成多个split(一个split是一个map的输入),每个split的长度都大于mapred.max.split.size, 因为以block为单位, 因此也会大于blockSize, 此文件剩下的长度如果大于mapred.min.split.size.per.node, 则生成一个split, 否则先暂时保留.b、现在剩下的都是一些长度效短的碎片,把每个rack下碎片合并, 只要长度超过mapred.max.split.size就合并成一个split, 最后如果剩下的碎片比mapred.min.split.size.per.rack大, 就合并成一个split, 否则暂时保留.c、把不同rack下的碎片合并, 只要长度超过mapred.max.split.size就合并成一个split, 剩下的碎片无论长度, 合并成一个split.</code></pre><p>举例: </p><pre><code>mapred.max.split.size=1000mapred.min.split.size.per.node=300mapred.min.split.size.per.rack=100输入目录下五个文件,rack1下三个文件,长度为2050,1499,10, rack2下两个文件,长度为1010,80\. 另外blockSize为500.经过第一步, 生成五个split: 1000,1000,1000,499,1000\. 剩下的碎片为rack1下:50,10; rack2下10:80由于两个rack下的碎片和都不超过100, 所以经过第二步, split和碎片都没有变化.第三步,合并四个碎片成一个split, 长度为150.如果要减少map数量, 可以调大mapred.max.split.size, 否则调小即可.其特点是: 一个块至多作为一个map的输入，一个文件可能有多个块，一个文件可能因为块多分给做为不同map的输入， 一个map可能处理多个块，可能处理多个文件。</code></pre><p><strong>2、reduce数量</strong></p><p>可以在hive运行sql的时，打印出来，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Number of reduce tasks not specified. Estimated from input data size: 1</span><br><span class="line"></span><br><span class="line">In order to change the average load for a reducer (in bytes):</span><br><span class="line"></span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"></span><br><span class="line">In order to limit the maximum number of reducers:</span><br><span class="line"></span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"></span><br><span class="line">In order to set a constant number of reducers:</span><br><span class="line"></span><br><span class="line">  set mapred.reduce.tasks=&lt;number&gt;</span><br></pre></td></tr></table></figure></p><p>reduce数量由以下三个参数决定：</p><pre><code>mapred.reduce.tasks (强制指定reduce的任务数量)hive.exec.reducers.bytes.per.reducer （每个reduce任务处理的数据量，默认为1000^3=1G)hive.exec.reducers.max（每个任务最大的reduce数，默认为999）计算reducer数的公式很简单N=min( hive.exec.reducers.max ，总输入数据量/ hive.exec.reducers.bytes.per.reducer )</code></pre><p>  只有一个reduce的场景：</p><pre><code>a、没有group by 的汇总b、order byc、笛卡尔积</code></pre><p><strong>二、join和Group的优化</strong></p><pre><code>对于普通的join操作，会在map端根据key的hash值，shuffle到某一个reduce上去，在reduce端做join连接操作，内存中缓存join左边的表，遍历右边的表，一次做join操作。所以在做join操作时候，将数据量多的表放在join的右边。当数据量比较大，并且key分布不均匀，大量的key都shuffle到一个reduce上了，就出现了数据的倾斜。对于Group操作，首先在map端聚合，最后在reduce端坐聚合，hive默认是这样的，以下是相关的参数 · hive.[map](http://www.verydemo.com/demo_c152_i9269.html).aggr = true是否在 Map 端进行聚合，默认为 True · hive.groupby.mapaggr.checkinterval = 100000在 Map 端进行聚合操作的条目数目</code></pre><p><strong>对于join和Group操作都可能会出现数据倾斜。</strong></p><pre><code>以下有几种解决这个问题的常见思路1、参数hive.groupby.skewindata = true,解决数据倾斜的万能钥匙，查询计划会有两个 MR [Job](http://www.verydemo.com/demo_c152_i9269.html)。第一个 MR Job 中，Map 的输出结果集合会随机分布到 Reduce 中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的 Group By Key 有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的；第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作。2、where的条件写在join里面，使得减少join的数量（经过map端过滤，只输出复合条件的）3、mapjoin方式，无reduce操作，在map端做join操作（map端cache小表的全部数据），这种方式下无法执行Full/RIGHT OUTER join操作4、对于count(distinct)操作，在map端以group by的字段和count的字段联合作为key，如果有大量相同的key，那么会存在数据倾斜的问题5、数据的倾斜还包括，大量的join连接key为空的情况，空的key都hash到一个reduce上去了，解决这个问题，最好把空的key和非空的key做区分，空的key不做join操作。当然有的hive操作，不存在数据倾斜的问题，比如数据聚合类的操作，像sum、count，因为已经在map端做了聚合操作了，到reduce端的数据相对少一些，所以不存在这个问题。</code></pre><p><strong>三、小文件的合并</strong></p><pre><code>大量的小文件导致文件数目过多，给HDFS带来压力，对hive处理的效率影响比较大，可以合并map和reduce产生的文件hive.merge.mapfiles = true                是否和并 Map 输出文件，默认为 Truehive.merge.mapredfiles = false            是否合并  Reduce 输出文件，默认为 Falsehive.merge.size.per.task = 256*1000*1000  合并文件的大小</code></pre><p><strong>四、in/exists（not）</strong></p><pre><code>通过left semi join 实现 in操作，一个限制就是join右边的表只能出现在join条件中</code></pre><p><strong>五、分区裁剪</strong></p><pre><code>通过在条件中指定分区，来限制数据扫描的范围，可以极大提高查询的效率</code></pre><p><strong>六、排序</strong></p><pre><code>order by 排序，只存在一个reduce，这样效率比较低。可以用sort by操作,通常结合distribute by使用做reduce分区键</code></pre><p>如想了解更多，请参考<strong>原文地址：<a href="https://blog.csdn.net/lovebyz/article/details/52096464" target="_blank" rel="noopener">HIVE的优化总结</a></strong></p><!-- </div> -->]]></content>
    
    <summary type="html">
    
      &lt;!-- &lt;div style=&quot;-webkit-box-shadow: 0 0 14px rgba(202,203,203,1);-moz-box-shadow: 0 0 14px rgba(202,203,204,1);
background: #fff;padding: 25px;margin-bottom: 100px;&quot;&gt; --&gt;
&lt;h1 id=&quot;HIVE的优化总结&quot;&gt;&lt;a href=&quot;#HIVE的优化总结&quot; class=&quot;headerlink&quot; title=&quot;HIVE的优化总结&quot;&gt;&lt;/a&gt;HIVE的优化总结&lt;/h1&gt;&lt;p&gt;Hive是将符合SQL语法的字符串解析生成可以在Hadoop上执行的MapReduce的工具。使用Hive尽量按照分布式计算的一些特点来设计sql，和传统关系型数据库有区别，&lt;/p&gt;
&lt;p&gt;所以需要去掉原有关系型数据库下开发的一些固有思维。&lt;/p&gt;
&lt;p&gt;基本原则：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、尽量尽早地过滤数据，减少每个阶段的数据量,对于分区表要加分区，同时只选择需要使用到的字段&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;select ... from A &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;join B&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;on A.key = B.key&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;where A.userid&amp;gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     and B.userid&amp;lt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     and A.dt=&amp;apos;20120417&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     and B.dt=&amp;apos;20120417&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;应该改写为：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;select .... from &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       (select .... from A&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        where dt=&amp;apos;201200417&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        and userid&amp;gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       ) a&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;join &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      ( select .... from B&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       where dt=&amp;apos;201200417&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       and userid &amp;lt; 10   &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      ) b&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;on a.key = b.key;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://www.gofunink.com/categories/Hive/"/>
    
    
      <category term="Hive优化" scheme="https://www.gofunink.com/tags/Hive%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>用MackDown语法写Hexo博客</title>
    <link href="https://www.gofunink.com/2017/11/10/%E7%94%A8MackDown%E8%AF%AD%E6%B3%95%E5%86%99hexo%E5%8D%9A%E5%AE%A2/"/>
    <id>https://www.gofunink.com/2017/11/10/用MackDown语法写hexo博客/</id>
    <published>2017-11-10T08:10:58.000Z</published>
    <updated>2019-04-08T07:42:54.200Z</updated>
    
    <content type="html"><![CDATA[<!-- <div style="-webkit-box-shadow: 0 0 14px rgba(202,203,203,1);-moz-box-shadow: 0 0 14px rgba(202,203,204,1);background: #fff;padding: 25px;margin-bottom: 100px;"> --><p><a href="http://www.jianshu.com" target="_blank" rel="noopener">「简书」</a>作为一款「写作软件」在诞生之初就支持了 Markdown，Markdown 是一种「电子邮件」风格的「标记语言」，我们强烈推荐所有写作者学习和掌握该语言。为什么？可以参考:</p><ul><li><p><a href="http://www.jianshu.com/p/qqGjLN" target="_blank" rel="noopener">『为什么作家应该用 Markdown 保存自己的文稿』</a>。</p></li><li><p><a href="http://www.jianshu.com/p/PpDNMG" target="_blank" rel="noopener">『Markdown写作浅谈』</a></p></li></ul><p>在此，我们总结 Markdown 的优点如下：</p><ul><li><p>纯文本，所以兼容性极强，可以用所有文本编辑器打开。</p></li><li><p>让你专注于文字而不是排版。</p></li><li><p>格式转换方便，Markdown 的文本你可以轻松转换为 html、电子书等。</p></li><li><p>Markdown 的标记语法有极好的可读性。</p></li></ul><p>当然，我们既然如此推崇 Markdown ，也必定会教会你使用 Markdown ，这也是本文的目的所在。不过，虽然 <a href="http://wowubuntu.com/markdown/" target="_blank" rel="noopener">Markdown 的语法</a>已经足够简单，但是现有的 Markdown 语法说明更多的是写给 web 从业者看的，对于很多写作者来说，学习起来效率很低，现在，我们特地为写作者量身定做本指南，从写作者的实际需求出发，介绍写作者真正实用的常用格式，深入浅出、图文并茂地让您迅速掌握 Markdown 语法。</p><p>为了使您更好地学习，我们建议您登录<a href="http://www.%20jianshu.com" target="_blank" rel="noopener">「简书」</a>，将您的编辑器切换至 Markdown 编辑器，新建一篇空白笔记，然后点击右上角的预览模式：</p><p><img src="http://upload-images.jianshu.io/upload_images/259-b7a1aa59aaca63e4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><p>此时，您的界面应当如下图所示，左侧为编辑区域，右侧为预览区域，您在左侧输入 Markdown 语法的文本，右侧会立即帮您呈现最终结果，好了，让我们开始学习吧~</p><p><img src="http://upload-images.jianshu.io/upload_images/259-05f6819ea5aa4fdd.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><a id="more"></a><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>这是最为常用的格式，在平时常用的的文本编辑器中大多是这样实现的：输入文本、选中文本、设置标题格式。</p><p>而在 Markdown 中，你只需要在文本前面加上 <code>#</code> 即可，同理、你还可以增加二级标题、三级标题、四级标题、五级标题和六级标题，总共六级，只需要增加 <code>#</code> 即可，标题字号相应降低。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br><span class="line">#### 四级标题</span><br><span class="line">##### 五级标题</span><br><span class="line">###### 六级标题</span><br></pre></td></tr></table></figure><p><em>注：<code>#</code> 和「一级标题」之间建议保留一个字符的空格，这是最标准的 Markdown 写法。</em></p><p><em>你可以你的编辑器中尝试输入这六级标题，可以参考下方的截图：</em></p><p><img src="http://upload-images.jianshu.io/upload_images/259-7424a9a21a2cb81b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>列表格式也很常用，在 Markdown 中，你只需要在文字前面加上 <code>-</code> 就可以了，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 文本1</span><br><span class="line">- 文本2</span><br><span class="line">- 文本3</span><br></pre></td></tr></table></figure><p>如果你希望有序列表，<br>也可以在文字前面加上 <code>1.</code> <code>2.</code> <code>3.</code> 就可以了，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">`1.` 文本1</span><br><span class="line">`2.` 文本2</span><br><span class="line">`3.` 文本3</span><br></pre></td></tr></table></figure><p><em>注：<code>-</code>、<code>1.</code>和文本之间要保留一个字符的空格。</em></p><p><em>列表案例截图如下：</em></p><p><img src="http://upload-images.jianshu.io/upload_images/259-8ccbfed8ce487368.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h2 id="链接和图片"><a href="#链接和图片" class="headerlink" title="链接和图片"></a>链接和图片</h2><p>在 Markdown 中，插入链接不需要其他按钮，你只需要使用 <code>[显示文本](链接地址)</code> 这样的语法即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[简书](http://www.jianshu.com)</span><br></pre></td></tr></table></figure><p>在 Markdown 中，插入图片不需要其他按钮，你只需要使用 <code>[图片上传失败...(image-5fdc5-1510890177031)]</code> 这样的语法即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![](http://upload-images.jianshu.io/upload_images/259-0ad0d0bfc1c608b6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)</span><br></pre></td></tr></table></figure><p><em>注：插入图片的语法和链接的语法很像，只是前面多了一个 <code>！</code>。</em></p><p><em>插入链接和图片的案例截图：</em></p><p><img src="http://upload-images.jianshu.io/upload_images/259-90ac0f366310f464.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>在我们写作的时候经常需要引用他人的文字，这个时候引用这个格式就很有必要了，在 Markdown 中，你只需要在你希望引用的文字前面加上 <code>&gt;</code> 就好了，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; 一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。</span><br></pre></td></tr></table></figure><p><em>注：<code>&gt;</code> 和文本之间要保留一个字符的空格。</em></p><p>最终显示的就是：</p><blockquote><p>一盏灯， 一片昏黄； 一简书， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。</p></blockquote><p><em>引用的案例截图：</em></p><p><img src="http://upload-images.jianshu.io/upload_images/259-438c3424cfbfb029.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h2 id="粗体和斜体"><a href="#粗体和斜体" class="headerlink" title="粗体和斜体"></a>粗体和斜体</h2><p>Markdown 的粗体和斜体也非常简单，用两个 <code>*</code> 包含一段文本就是粗体的语法，用一个 <code>*</code> 包含一段文本就是斜体的语法。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*一盏灯*， 一片昏黄；**一简书**， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。</span><br></pre></td></tr></table></figure><p>最终显示的就是下文，其中「一盏灯」是斜体，「一简书」是粗体：</p><p> <em>一盏灯</em>， 一片昏黄；<strong>一简书</strong>， 一杯淡茶。 守着那一份淡定， 品读属于自己的寂寞。 保持淡定， 才能欣赏到最美丽的风景！ 保持淡定， 人生从此不再寂寞。</p><p><em>粗体和斜体的案例截图：</em></p><p><img src="http://upload-images.jianshu.io/upload_images/259-6a74e417a86ac97f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h2 id="代码引用"><a href="#代码引用" class="headerlink" title="代码引用"></a>代码引用</h2><p>需要引用代码时，如果引用的语句只有一段，不分行，可以用 ` 将语句包起来。<br>如果引用的语句为多行，可以将<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*代码引用的案例截图：*</span><br><span class="line"></span><br><span class="line">![](http://upload-images.jianshu.io/upload_images/259-dcf737a97e71cd73.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)</span><br><span class="line"></span><br><span class="line">##表格</span><br><span class="line"></span><br><span class="line">相关代码：</span><br></pre></td></tr></table></figure></p><table><thead><tr><th>Tables</th><th style="text-align:center">Are</th><th style="text-align:right">Cool</th></tr></thead><tbody><tr><td>col 3 is</td><td style="text-align:center">right-aligned</td><td style="text-align:right">$1600</td></tr><tr><td>col 2 is</td><td style="text-align:center">centered</td><td style="text-align:right">$12</td></tr><tr><td>zebra stripes</td><td style="text-align:center">are neat</td><td style="text-align:right">$1</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">显示效果：</span><br><span class="line"></span><br><span class="line">|Tables        | Are           | Cool  |</span><br><span class="line">| ------------- |:-------------:| -----:|</span><br><span class="line">| col 3 is      | right-aligned | $1600 |</span><br><span class="line">| col 2 is      | centered      |   $12 |</span><br><span class="line">| zebra stripes | are neat      |    $1 |</span><br><span class="line"></span><br><span class="line">相关代码：</span><br></pre></td></tr></table></figure><table><thead><tr><th>dog</th><th>bird</th><th>cat</th></tr></thead><tbody><tr><td>foo</td><td>foo</td><td>foo</td></tr><tr><td>bar</td><td>bar</td><td>bar</td></tr><tr><td>baz</td><td>baz</td><td>baz</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">显示效果：</span><br><span class="line"></span><br><span class="line">dog | bird | cat</span><br><span class="line">----|------|----</span><br><span class="line">foo | foo | foo</span><br><span class="line">bar | bar | bar</span><br><span class="line">baz | baz | baz</span><br><span class="line"></span><br><span class="line">## 显示链接中带括号的图片</span><br><span class="line"></span><br><span class="line">![](http://latex.codecogs.com/gif.latex?%5Cprod%20%5C(n_%7Bi%7D%5C)+1)</span><br><span class="line"></span><br><span class="line">代码如下:</span><br></pre></td></tr></table></figure><p>![][1]<br>[1]: <a href="http://latex.codecogs.com/gif.latex?\prod%20\(n_{i}\)+1" target="_blank" rel="noopener">http://latex.codecogs.com/gif.latex?\prod%20\(n_{i}\)+1</a><br><code>`</code></p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>以上几种格式是比较常用的格式，所以我们针对这些语法做了比较详细的说明。除这些之外，Markdown 还有其他语法，如想了解和学习更多，可以参考这篇<a href="http://wowubuntu.com/markdown/" target="_blank" rel="noopener">『Markdown 语法说明』</a>。</p><p>原文作者：简书 链接：<a href="http://www.jianshu.com/p/q81RER" target="_blank" rel="noopener">http://www.jianshu.com/p/q81RER</a></p><!-- </div> -->]]></content>
    
    <summary type="html">
    
      &lt;!-- &lt;div style=&quot;-webkit-box-shadow: 0 0 14px rgba(202,203,203,1);-moz-box-shadow: 0 0 14px rgba(202,203,204,1);
background: #fff;padding: 25px;margin-bottom: 100px;&quot;&gt; --&gt;
&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;「简书」&lt;/a&gt;作为一款「写作软件」在诞生之初就支持了 Markdown，Markdown 是一种「电子邮件」风格的「标记语言」，我们强烈推荐所有写作者学习和掌握该语言。为什么？可以参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com/p/qqGjLN&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;『为什么作家应该用 Markdown 保存自己的文稿』&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com/p/PpDNMG&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;『Markdown写作浅谈』&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在此，我们总结 Markdown 的优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;纯文本，所以兼容性极强，可以用所有文本编辑器打开。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;让你专注于文字而不是排版。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;格式转换方便，Markdown 的文本你可以轻松转换为 html、电子书等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Markdown 的标记语法有极好的可读性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然，我们既然如此推崇 Markdown ，也必定会教会你使用 Markdown ，这也是本文的目的所在。不过，虽然 &lt;a href=&quot;http://wowubuntu.com/markdown/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Markdown 的语法&lt;/a&gt;已经足够简单，但是现有的 Markdown 语法说明更多的是写给 web 从业者看的，对于很多写作者来说，学习起来效率很低，现在，我们特地为写作者量身定做本指南，从写作者的实际需求出发，介绍写作者真正实用的常用格式，深入浅出、图文并茂地让您迅速掌握 Markdown 语法。&lt;/p&gt;
&lt;p&gt;为了使您更好地学习，我们建议您登录&lt;a href=&quot;http://www.%20jianshu.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;「简书」&lt;/a&gt;，将您的编辑器切换至 Markdown 编辑器，新建一篇空白笔记，然后点击右上角的预览模式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/259-b7a1aa59aaca63e4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;此时，您的界面应当如下图所示，左侧为编辑区域，右侧为预览区域，您在左侧输入 Markdown 语法的文本，右侧会立即帮您呈现最终结果，好了，让我们开始学习吧~&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/259-05f6819ea5aa4fdd.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="MackDown" scheme="https://www.gofunink.com/categories/MackDown/"/>
    
      <category term="Hexo" scheme="https://www.gofunink.com/categories/MackDown/Hexo/"/>
    
    
      <category term="MarkDown" scheme="https://www.gofunink.com/tags/MarkDown/"/>
    
      <category term="Hexo" scheme="https://www.gofunink.com/tags/Hexo/"/>
    
  </entry>
  
</feed>
